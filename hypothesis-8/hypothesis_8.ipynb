{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predefined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Getting data\n",
    "def getData(url, sheet_name=0, skiprows=0, truncate=-1, index_column='County Name'):\n",
    "    df = pd.read_excel(url, sheet_name=sheet_name, skiprows=skiprows)\n",
    "    if truncate > -1:\n",
    "        df = df.truncate(before=0, after=truncate)\n",
    "    df = df.set_index(index_column)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_subplot(ax, label, fontsize=12, ticker_count=3):\n",
    "    # axis label\n",
    "    ax.set_title(label, fontdict={'fontsize':fontsize})\n",
    "    # number of tickers\n",
    "    ax.xaxis.set_major_locator(ticker.MaxNLocator(ticker_count))\n",
    "    # ticker formatter\n",
    "    ax.xaxis_date()\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%b\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative case count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://dshs.texas.gov/coronavirus/TexasCOVID19DailyCountyCaseCountData.xlsx\"\n",
    "cases_df = getData(url, skiprows=2, truncate=253)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile('[0-9]+-[0-9]+', re.IGNORECASE)\n",
    "cases_df.columns = [pattern.findall(sub)[0] for sub in cases_df.keys()]\n",
    "\n",
    "from datetime import datetime\n",
    "dates = [datetime.strptime(date, '%m-%d') for date in cases_df.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data down to per 100k capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_url = \"https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/totals/co-est2019-alldata.csv\"\n",
    "pop_df = pd.read_csv(pop_url, engine='python')\n",
    "pop_df = pop_df.rename(columns={'CTYNAME': 'County Name'})\n",
    "pop_df = pop_df.set_index('County Name')\n",
    "# filter Texas counties\n",
    "pop_df = pop_df[pop_df['STNAME'] == 'Texas']\n",
    "# get latest population\n",
    "pop_df = pop_df[pop_df.filter(like='2019').columns[0]]\n",
    "# remove suffix ' County' in name\n",
    "pop_df.index = pop_df.index.map(lambda x: x.replace(' County', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaled_cases_df = cases_df.apply(lambda row: row * 1e5 / pop_df[row.index])\n",
    "scaled_cases_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metro / Non-metro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is retrieved from 2013 NCHS Urban–Rural Classification Scheme, in which six levels scheme are defined according to the\n",
    "following classification rules:\n",
    "### Metropolitan categories\n",
    "\n",
    "**Large central metro**—Counties in MSAs of 1 million or more population that:\n",
    "1.\t Contain the entire population of the largest principal city of the MSA, or\n",
    "2.\t Have their entire population contained in the largest principal city of the MSA, or\n",
    "3.\t Contain at least 250,000 inhabitants of any principal city of the MSA.\n",
    "\n",
    "**Large fringe metro**—Counties in MSAs of 1 million or more population that did not qualify as large central metro counties.\n",
    "\n",
    "**Medium metro**—Counties in MSAs of populations of 250,000 to 999,999.  \n",
    "\n",
    "**Small metro**—Counties in MSAs of populations less than 250,000.\n",
    "\n",
    "### Nonmetropolitan categories\n",
    "\n",
    "**Micropolitan**—Counties in micropolitan statistical areas.\n",
    "\n",
    "**Noncore**—Nonmetropolitan counties that did not qualify as micropolitan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metro_url = \"http://www.dshs.state.tx.us/chs/info/TxCoPhrMsa.xls\"\n",
    "metro_df = getData(metro_url, truncate=253)\n",
    "metro_df = metro_df[[metro_df.filter(like='2013').columns[0], metro_df.filter(like='Metro Area').columns[0]]]\n",
    "#metro_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging all into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# population\n",
    "merged_df = pd.merge(pop_df, metro_df, on='County Name', how='inner')\n",
    "# metro classificiation\n",
    "merged_df = pd.merge(merged_df, scaled_cases_df, on='County Name', how='outer')\n",
    "# rename column\n",
    "keys = merged_df.keys()\n",
    "merged_df = merged_df.rename(columns={keys[0]: 'Population', keys[1]: 'Classification', keys[2]: 'MetroArea'})\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "figsize=(20,10)\n",
    "title_size = 24\n",
    "label_size = 18\n",
    "ticker_count= 8\n",
    "line_width = 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-day average daily case count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure\n",
    "fig = plt.figure(figsize=figsize, dpi=60)\n",
    "fig.suptitle('7-day average daily case count per 100,000 of population', fontsize=32)\n",
    "# and its subplots\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "config_subplot(ax1, 'NCHS Urban-Rural classificiation (2013)', title_size, ticker_count)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "config_subplot(ax2, 'Metro Area', title_size, ticker_count)\n",
    "\n",
    "# plotting average values of each metro classification\n",
    "# for label, df in merged_df.groupby('Classification', sort=True):\n",
    "metro_cls = ['Non-core', 'Micropolitan', 'Small Metro', 'Medium Metro', 'Large Fringe Metro', 'Large Central Metro']\n",
    "for cls in metro_cls:\n",
    "    df = merged_df[merged_df['Classification'] == cls].iloc[:,3:]\n",
    "    df = df.mean().diff().rolling(window=7).mean()\n",
    "    #print(df.iloc[:,:-1].max().max())\n",
    "    ax1.plot(dates, df, label=cls, linewidth=line_width)\n",
    "\n",
    "# plotting average values of each metro classification\n",
    "metro_types = ['Non-Metro', 'Metro']\n",
    "for metro_type in metro_types:\n",
    "    df = merged_df[merged_df['MetroArea'] == metro_type].iloc[:,3:]\n",
    "    df = df.mean().diff().rolling(window=7).mean()\n",
    "    ax2.plot(dates, df, label=metro_type, linewidth=line_width)\n",
    "\n",
    "# using same ylim\n",
    "# ax1.set_ylim(0, 45);\n",
    "# ax2.set_ylim(0, 45);\n",
    "    \n",
    "# configure legend\n",
    "handles, labels = ax1.get_legend_handles_labels()\n",
    "ax1.legend(handles, labels, loc='upper left', fontsize='xx-large')\n",
    "handles, labels = ax2.get_legend_handles_labels()\n",
    "ax2.legend(handles, labels, loc='upper left', fontsize='xx-large')\n",
    "\n",
    "# configure legend on lines\n",
    "for line, name in zip(ax1.lines, metro_cls):\n",
    "    y = line.get_ydata()[-1]\n",
    "    ax1.annotate(name, xy=(1,y), xytext=(6,0), color=line.get_color(), \n",
    "                xycoords = ax1.get_yaxis_transform(), textcoords=\"offset points\",\n",
    "                size=14, va=\"center\")\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.87)\n",
    "\n",
    "fig.savefig('../graphs/hypothesis_8_1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrary to the hypothesis, the daily number of new cases of rural counties appears to be a little higher than those urban ones, especially with micropolitan counties top the graph during the outbreak period. Small-metro counties seems to has least spread, while other types are somewhat similar to each other.\n",
    "\n",
    "When we combine them into 2 main caterogies metro or non-metro, it even becomes clearer when those metro counties are almost always equal or lower than non-metro counterparts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating average daily cases by month "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "\n",
    "avg_month_df = merged_df.iloc[:,:3]\n",
    "for month in range(1,12,1):\n",
    "    df = merged_df.filter(like='{:02d}-'.format(month))\n",
    "    if df.shape[1] > 0:\n",
    "        avg_month_df[calendar.month_name[month]] = df.mean(axis=1).values\n",
    "# avg_month_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "# configure figure\n",
    "fig_size = 6\n",
    "fig2 = plt.figure(figsize=(fig_size*3, fig_size*1.5))\n",
    "fig2.suptitle('Cumulative case count (per 100,000 of population)', fontsize=title_size)\n",
    "# fig2.text(0.085, 0.5, \"Cumulative case count (per 100,000 of population)\", va=\"center\", rotation=90, fontsize=14)\n",
    "\n",
    "# determine y-lim\n",
    "vmax = merged_df.iloc[:,3:].max().max()\n",
    "\n",
    "idx = 0\n",
    "for i, metro_type in enumerate(metro_types):\n",
    "    # filter by metro area\n",
    "    avg_month_type_df = avg_month_df[avg_month_df['MetroArea'] == metro_type].iloc[:,3:]\n",
    "    for month in avg_month_type_df:\n",
    "        # padding\n",
    "        col = avg_month_type_df[month].values\n",
    "        col = np.pad(col, (0, 10 - col.shape[0] % 10), 'constant')\n",
    "        col = col.reshape((-1,10))\n",
    "        # plotting\n",
    "        idx += 1\n",
    "        ax = fig2.add_subplot(2, 7, idx)\n",
    "        ax.set_title(month, fontdict={'fontsize':12})\n",
    "        heatmap = ax.imshow(col, cmap=cm.Reds, vmax=vmax)\n",
    "        ax.set_axis_off()\n",
    "        \n",
    "# configure colorbar\n",
    "fig2.subplots_adjust(bottom=0.2)\n",
    "fig2.colorbar(heatmap, orientation=\"horizontal\", fraction=0.07,anchor=(1.0,0.0))\n",
    "\n",
    "fig2.savefig('../graphs/hypothesis_8_2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at corresponding heatmap of those two types, we can clearly see that there is also way many more counties with darker color in non-metro type, indicating greater spread compared to metro counties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melting Daily into Month for easier plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_avg_month_df = avg_month_df.drop(avg_month_df.keys()[3], axis=1)\n",
    "keys = melt_avg_month_df.keys()\n",
    "melt_avg_month_df = pd.melt(melt_avg_month_df, id_vars=keys[:3], value_vars=keys[3:], var_name='Month', value_name='Daily')\n",
    "# melt_avg_month_df.sort_values(by=['Population'])\n",
    "melt_avg_month_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "g = sns.lmplot(data=melt_avg_month_df, col='Month', x='Population', y='Daily', scatter=True,\n",
    "               hue='Classification', col_wrap=3, ci=40, scatter_kws={'linewidths':1, 'edgecolor':'w'})\n",
    "\n",
    "# log xscale and set axis limits\n",
    "pop = melt_avg_month_df['Population']\n",
    "daily = melt_avg_month_df['Daily']\n",
    "g.set(xlim=(pop.min(), pop.max()), ylim=(daily.min(), daily.max()), xscale='log')\n",
    "\n",
    "# add title\n",
    "fig4 = g.fig\n",
    "fig4.subplots_adjust(top=0.9)\n",
    "fig4.suptitle('Cumulative case count (per 100,000 of population)', fontsize=title_size)\n",
    "\n",
    "g.savefig('../graphs/hypothesis_8_3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "# cols=3\n",
    "# fig3, axes = plt.subplots(2, cols, figsize=(15,10))\n",
    "# fig3.suptitle('Cumulative case count (per 100,000 of population)', fontsize=title_size)\n",
    "\n",
    "# ylim = avg_month_df.iloc[:,3:].max().max()\n",
    "# for month in range(4, 10, 1):\n",
    "#     idx = month - 4\n",
    "#     ax = axes[int(idx/cols)][idx%cols]\n",
    "#     ax.set_ylim(0, ylim);\n",
    "#     g = sns.scatterplot(data=avg_month_df, x=\"Population\", y=calendar.month_name[month], hue='Classification', ax=ax)\n",
    "#     g.set(xscale=\"log\")\n",
    "#     ax.get_legend().remove()\n",
    "    \n",
    "# handles, labels = axes[1][2].get_legend_handles_labels()\n",
    "# fig3.legend(handles, labels, loc='upper right')\n",
    "\n",
    "# fig3.savefig('../graphs/hypothesis_8_4.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing statistical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null hypothesis (H0): There is no difference between spread rate of rural and urban counties.  \n",
    "Alternative hypothesis (H1): Rural counties had different spread rate from urban counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import time\n",
    "np.random.seed(int(time.time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paired T-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into metro and non-metro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_metro_df = merged_df[merged_df['MetroArea'] == 'Metro'].iloc[:,3:].mean()\n",
    "case_non_metro_df = merged_df[merged_df['MetroArea'] == 'Non-Metro'].iloc[:,3:].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then perform paired T-Test on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.ttest_ind(case_non_metro_df.mean(), case_metro_df.mean(), equal_var = False)\n",
    "stats.ttest_rel(case_non_metro_df, case_metro_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is 0.001, which is less than the stardard threshold 0.05 and 0.01, so we reject the null hypothesis and we can say that rural counties had different spread rate from urban ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-square test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a second thought, chi-square test might not be suitable for this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_not_zero = max((case_metro_df != 0).idxmax(), (case_non_metro_df != 0).idxmax())\n",
    "# no_zero_metro_df = case_metro_df[first_not_zero:]\n",
    "# no_zero_non_metro_df = case_non_metro_df[first_not_zero:]\n",
    "# max_case = max(no_zero_metro_df[-1], no_zero_non_metro_df[-1])\n",
    "\n",
    "max_case = max(case_metro_df[-1], case_non_metro_df[-1])\n",
    "interval = 400\n",
    "intervals = range(0, int(max_case + interval), interval)\n",
    "expected = case_metro_df.groupby(pd.cut(case_metro_df, intervals)).count()\n",
    "observed = case_non_metro_df.groupby(pd.cut(case_non_metro_df, intervals)).count()\n",
    "\n",
    "#stats.chisquare(case_metro_df.mean(), case_non_metro_df.mean(), ddof=case_metro_df.shape[0]-1)\n",
    "stats.chisquare(observed.values, f_exp=expected, ddof=observed.shape[0]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attemp to split data into 3 categories: small, medium and large population, then perform ANOVA on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = merged_df['Classification']\n",
    "rural = merged_df[cls.isin(['Non-core', 'Micropolitan'])].iloc[:,3:]\n",
    "mixed = merged_df[cls.isin(['Small Metro', 'Medium Metro'])].iloc[:,3:]\n",
    "urban = merged_df[cls.isin(['Large Fringe Metro', 'Large Central Metro'])].iloc[:,3:]\n",
    "stats.f_oneway(rural.mean(), mixed.mean(), urban.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the same approach as above, but use all 5 classifications instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.f_oneway(*merged_df.groupby('Classification').mean().values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both results are much larger than standard thresholds, so we do not have enough evidence to reject the hypothesis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
